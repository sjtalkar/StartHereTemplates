{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Template store of data cleaning functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Typical Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The basics\n",
    "#import pandas_profiling\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#FOr Stats\n",
    "from scipy import stats as ss\n",
    "\n",
    "\n",
    "\n",
    "#For visualizations\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#For Color map\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "#For widgets using interact\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Getting a feel for the data at a glance</h2>\n",
    " \n",
    "<h4>quart_df.info() </h4>\n",
    "<p>quart_df.describe</p>\n",
    "<p>quart_df.shape</p>\n",
    "<p>quart_df.head()</p>\n",
    "<p>quart_df.tail()</p>    \n",
    "    \n",
    "* Check if any column has unique values \n",
    "<p>for i in column_names:\n",
    "  print('{} is unique: {}'.format(i, df[i].is_unique))</p>\n",
    "    \n",
    "* Check for index if any\n",
    "   <p>df.index.values</p>\n",
    "\n",
    "* Check if a certain index exists\n",
    "<p>'foo' in df.index.values</p>\n",
    " \n",
    "* If index does not exist\n",
    "<p>df.set_index('column_name_to_use', inplace=True)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-warning'>\n",
    "    <a href = 'https://medium.com/@rrfd/cleaning-and-prepping-data-with-python-for-data-science-best-practices-and-helpful-packages-af1edfbe2a3'> A comprehensive workflow for data cleaning</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "<a href='https://github.com/sjtalkar/StartHereTemplates/blob/master/DataManipulationExercises.ipynb'><h3>Quick and varied manipulations of dataframe and columns</h3></a>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Event handling\n",
    "* Create a callback function \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "def onclick_response(event):\n",
    "   <p>     plt.title('Event handling at pixel {},  {}  and data {}, {} '.format(event.x, event.y, \n",
    "                <p>np.round(event.xdata, 2), np.round(event.ydata, 2)), fontsize='small')<\\p>\n",
    "    <p>    return\n",
    "</div>\n",
    "\n",
    "\n",
    "* Link it to the figure\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "fig.canvas.mpl_connect('button_press_event',onclick_response)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Use decorator interact with appropriate argument for widget type (lists for drop downs, vboolean for  checkboxes )\n",
    "\n",
    "<p>@interact(x=\"42000\")\n",
    "<p>def compareUserThreshold(user_threshold=\"42000\"):\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using assert to check if values in a column are as expected \n",
    "\n",
    "Let’s test if all the values in col1 are >= 0 by using the built in method assert which comes with the standard library in python. What you’re asking python if is True all the items in df[‘col1'] are greater than zero. If this is True then continue on your way, if not throw an error.\n",
    "\n",
    "<code>\n",
    "assert(df['col1'] >= 0 ).all() # Should return nothing\n",
    "    \n",
    "What about testing the two columns to see if they are equal?\n",
    "assert(df['col1'] == df['col2']).all()\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas testing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Series are different\n\nAttribute \"name\" are different\n[left]:  col1\n[right]: col2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0f45405f56d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'col2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_series_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[1;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Series are different\n\nAttribute \"name\" are different\n[left]:  col1\n[right]: col2"
     ]
    }
   ],
   "source": [
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'col1':[1, 2, 3, 4,5], 'col2':[1, 2, 3, 4, 5]})\n",
    "\n",
    "df2 = pd.DataFrame({'col1':[1, 2, 3, 4,5], 'col2':[1, 2, 3, 4, 5]})\n",
    "\n",
    "tm.assert_series_equal(df1['col1'], df2['col2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking a dataframe to a dictionary through a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "zillow_allhomes_df  = pd.read_csv(r'City_Zhvi_AllHomes.csv')\n",
    "zillow_allhomes_df.head()\n",
    "\n",
    "zillow_allhomes_df.loc[:, 'State'] = zillow_allhomes_df.loc[:, 'State'].map(states)\n",
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado'\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby and Pivots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "    \n",
    "<p>Techniques for Working with Pivots¶\n",
    "<p>Add a new column so that that counts can be displayed based on its unique values (This is for two column dfs)\n",
    "<p>Pivot the table with index, columns and counts as values\n",
    "<p>Flatten the multilevel column index    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Group by \n",
    "<code style=\"background:grey;color:black\">\n",
    "dropMean_df = df.groupby('Team').agg({'Drops':'mean'})\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the pivot and merge multilevel index\n",
    "\n",
    "<code style=\"background:grey;color:black\">\n",
    "outcome_df = df.pivot_table(values=['Result'], index=['Group'], columns= ['Outcome'], aggfunc=['count'])\n",
    "#Combine the multilevel column name into one    \n",
    "outcome_df.columns = ['_'.join(col).strip() for col in outcome_df.columns.values]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new row at bottom of pivot dataframe\n",
    "<code style=\"background:grey;color:black\">\n",
    "new_row = {'Group' :'Observed_Difference' , 'count_Result_Failure' : FailureDiff, 'count_Result_Success': SuccessDiff, 'Total Count' : TotalDiff, 'avg_Success' : AvgDiff}\n",
    "outcome_df = outcome_df.append(new_row, ignore_index=True)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding margin totals to a pivot\n",
    "\n",
    "`df.pivot_table(values=['Price', 'Rating'], index='Manufacturer', columns='Bike Type', aggfunc=[np.mean], margins=True)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Using Where`\n",
    "*     Create a new column called based on the value of another column\n",
    "`df[\"Outcome\"] = np.where(df['Result'] == 0, 'Failure', 'Success')`\n",
    "\n",
    "` Three level nesting with np.where`\n",
    "`np.where(if_this_condition_is_true_one, do_this, \n",
    "  np.where(if_this_condition_is_true_two, do_that, \n",
    "    np.where(if_this_condition_is_true_three, do_foo, do_bar)))`\n",
    "    \n",
    "\n",
    "*  Using Between\n",
    "\n",
    "    `bool_series = data[\"Salary\"].between(80000, 100000, inclusive = True) \n",
    "`  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rowwise/along row stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:grey;color:black\">\n",
    "Send the row in to this function using apply\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\">\n",
    "def row_stats(row):\n",
    "    data = row[['count_Result_Success','count_Result_Failure']]\n",
    "    return pd.Series({'Total Count': np.sum(data)})\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\">\n",
    "apply the function to each row, note the axis\n",
    "outcome_df['Total Count'] = outcome_df.apply(row_stats, axis = 1)\n",
    "\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire dataframe stats - note the axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:grey;color:black\">\n",
    "df.mean(axis = 1) # Along the columns\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text file with hierachical data - states followed by cities cleaned to state-city columns\n",
    "\n",
    "<code style=\"background:grey;color:black\">\n",
    "  state_town_tuple_list = []\n",
    "    with open(r'university_towns.txt') as fref:\n",
    "        for line in fref:\n",
    "            lineWithoutSquare = line.split('[')[0].strip()\n",
    "            if ':' in lineWithoutSquare and not ('(')  in lineWithoutSquare :\n",
    "                continue\n",
    "            else:\n",
    "                if not ('(')  in lineWithoutSquare:\n",
    "                    state = lineWithoutSquare\n",
    "                else:\n",
    "                    univTown = lineWithoutSquare.split(' (')[0].strip().split(',')[0].strip()\n",
    "                    state_town_tuple_list.append((state, univTown) )\n",
    "</code>    \n",
    "<code style=\"background:grey;color:black\">               \n",
    "        state_univtown_df = pd.DataFrame(state_town_tuple_list, columns =['State', 'RegionName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absent data or Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame({'a': ['1?', '2?', '3'], 'b': ['4?', '?', '6?']})\n",
    "    \n",
    " print(df)\n",
    "\n",
    "df.replace({r'?': np.NaN}, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find what is at a certain row and column\n",
    "<code>\n",
    "df.at[df.index[df['Country'] == 'Africa'].values[0], 'Total confirmed cases']\n",
    "<code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify header, number of lines from bottom to ignore and drop columns and rows\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
    "</div>\n",
    "<code style=\"background:grey;color:black\">\n",
    "GDP_qtr = pd.read_excel(r'gdplev.xls', skiprows= 5)\n",
    "GDP_qtr= GDP_qtr.dropna(axis=0,how='all').dropna(axis=1,how='all').iloc[:,3:]\n",
    "Only drop columns which have at least 90% non-NaNs\n",
    "df.dropna(thresh=int(df.shape[0] * .9), axis=1)\n",
    "</code>     \n",
    "<code style=\"background:grey;color:black\"> \n",
    "Drop columns\n",
    "    Create list comprehension of the columns you want to lose\n",
    "    columns_to_drop = [column_names[i] for i in [1, 3, 5]]\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\"> \n",
    "     Drop unwanted columns\n",
    "    df.drop(columns_to_drop, inplace=True, axis=1)\n",
    "</code>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Iterating through a dataset\n",
    "<code style=\"background:grey;color:black\">\n",
    "    for i, row in GDP_qtr.iterrows():\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving data of a column and not the series\n",
    "\n",
    "`test.loc[:0, 1992] \n",
    "0   -8941.531897\n",
    "Name: 1992, dtype: float64    \n",
    "`    \n",
    "   \n",
    "`df['column'].item()\n",
    "-8941.531896942593    \n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LaTeX MATH\n",
    "\n",
    "Jupyter Notebooks’ Markdown cells support LateX for formatting mathematical equations. To tell Markdown to interpret your text as LaTex, surround your input with dollar signs like this:\n",
    "\n",
    "`$\\sqrt{k}$`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine Index for a certain column value\n",
    "\n",
    "`GDP_qtr[GDP_qtr['YearQuarters']==recessionStart].index.item()\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reading lines from a file\n",
    "\n",
    "` with open(r'university_towns.txt') as fref:\n",
    "        for line in fref:`\n",
    "        \n",
    "        \n",
    "`f.seek(n)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and joins\n",
    "\n",
    "* PeriodIndex columns need to be changed in value to STR for Merge and Joins\n",
    "\n",
    "     `month_names = pd.PeriodIndex(month_names, freq='Q') `\n",
    "\n",
    "    `temp_zillow.columns = month_names`\n",
    "    \n",
    "    `#Makes ure the data in the periodindex columns are converted to str so that Merge and Join do not throw an error  `\n",
    "    `temp_zillow.columns.values.astype('str')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of a merge\n",
    "\n",
    "` univ_towns_housing = pd.merge(housing_data, univ_towns, how=\"left\", left_index=True, right_index=True)\n",
    "   `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String operations\n",
    "\n",
    "\n",
    "`[w for w in list if len(w) > 3]`\n",
    "\n",
    "*For Capitalized first letter\n",
    "`w.istitle(), isupper() .islower()`\n",
    "`.split, .strip()`\n",
    "\n",
    "`startswith(), endswith()`\n",
    "`t in s`\n",
    "\n",
    "`isalpha, isdigits(), isalnum()`\n",
    "\n",
    "`s.lower(), s.upper()m s.titlecase()`\n",
    "\n",
    "`s.splitlines()`\n",
    "`s.join(t)`\n",
    "\n",
    "`s.strip(), s.rstrip()   will also remove new line character`\n",
    "\n",
    "`s.find(), s.rfind()`\n",
    "\n",
    "`list(someword)  splits the word into characters   or [c for c in someword]`\n",
    "\n",
    "`s.replace('o', 'O')`\n",
    "\n",
    "`[w  for w in somelist of delimited words if w.startswith('#')]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular expression\n",
    "\n",
    "`import re`\n",
    "\n",
    "`re.search('[a-zA-A0-9_]+', s)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating a new column using ASSIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.assign(text_length = df['text'].apply(len))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the value counts for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = auto_prices['make'].value_counts() # find the counts for each unique category\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Unicodes and Dedpes using ML\n",
    "[Click here to check out the Unicodes section ](https://medium.com/@rrfd/cleaning-and-prepping-data-with-python-for-data-science-best-practices-and-helpful-packages-af1edfbe2a3)\n",
    "\n",
    "https://medium.com/district-data-labs/basics-of-entity-resolution-with-python-and-dedupe-bc87440b64d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram bins with value_counts() similar to pd.cut\n",
    "\n",
    "train['Fare'].value_counts(bins=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TIPS AND TRICKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<h4> Pretty Print </h4>    \n",
    "<p>import pprint as pp\n",
    "<p>pp.pprint (df)\n",
    "\n",
    "    \n",
    "<h4> Undo a delete </h4>    \n",
    " <li> Contents :  CTRL + Z</li>\n",
    " <li> Entire Cell :  ESC+Z  </li>   \n",
    "\n",
    "    \n",
    "<li> Esc + M to create a markdown\n",
    "    \n",
    "<li> Shift + Enter to run and create new cell below </li>    \n",
    "    \n",
    "<li> Find the dataframes in a notebook </li>\n",
    "    \n",
    "<p> listDF = %who_ls DataFrame </p>\n",
    "<h4> Display Options </h4> \n",
    "<div>    \n",
    "<p>pd.set_option('display.max_columns', 10)\n",
    "<p>pd.set_option('display.max_rows', 10)\n",
    "</div>\n",
    "    \n",
    "    \n",
    "<h4> Find and replace in all cells in Jupyter notebook </h4>\n",
    "    * Edit-> Find and replace Click double sided arrow\n",
    "    \n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "py_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
