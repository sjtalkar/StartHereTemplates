{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Template store of data cleaning functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Typical Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The basics\n",
    "#import pandas_profiling\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#FOr Stats\n",
    "from scipy import stats as ss\n",
    "\n",
    "\n",
    "\n",
    "#For visualizations\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#For Color map\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "#For widgets using interact\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Getting a feel for the data at a glance</h2>\n",
    " \n",
    "<h4>quart_df.info() </h4>\n",
    "<p>quart_df.describe</p>\n",
    "<p>quart_df.shape</p>\n",
    "<p>quart_df.head()</p>\n",
    "<p>quart_df.tail()</p>    \n",
    "    \n",
    "* Check if any column has unique values \n",
    "<p>for i in column_names:\n",
    "  print('{} is unique: {}'.format(i, df[i].is_unique))</p>\n",
    "    \n",
    "* Check for index if any\n",
    "   <p>df.index.values</p>\n",
    "\n",
    "* Check if a certain index exists\n",
    "<p>'foo' in df.index.values</p>\n",
    " \n",
    "* If index does not exist\n",
    "<p>df.set_index('column_name_to_use', inplace=True)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-warning'>\n",
    "    <a href = 'https://medium.com/@rrfd/cleaning-and-prepping-data-with-python-for-data-science-best-practices-and-helpful-packages-af1edfbe2a3'> A comprehensive workflow for data cleaning</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "<a href='https://github.com/sjtalkar/StartHereTemplates/blob/master/DataManipulationExercises.ipynb'><h3>Quick and varied manipulations of dataframe and columns</h3></a>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Event handling\n",
    "* Create a callback function \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "def onclick_response(event):\n",
    "   <p>     plt.title('Event handling at pixel {},  {}  and data {}, {} '.format(event.x, event.y, \n",
    "                <p>np.round(event.xdata, 2), np.round(event.ydata, 2)), fontsize='small')<\\p>\n",
    "    <p>    return\n",
    "</div>\n",
    "\n",
    "\n",
    "* Link it to the figure\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "fig.canvas.mpl_connect('button_press_event',onclick_response)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Use decorator interact with appropriate argument for widget type (lists for drop downs, vboolean for  checkboxes )\n",
    "\n",
    "<p>@interact(x=\"42000\")\n",
    "<p>def compareUserThreshold(user_threshold=\"42000\"):\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using assert to check if values in a column are as expected \n",
    "\n",
    "Let’s test if all the values in col1 are >= 0 by using the built in method assert which comes with the standard library in python. What you’re asking python if is True all the items in df[‘col1'] are greater than zero. If this is True then continue on your way, if not throw an error.\n",
    "\n",
    "<code>\n",
    "assert(df['col1'] >= 0 ).all() # Should return nothing\n",
    "    \n",
    "What about testing the two columns to see if they are equal?\n",
    "assert(df['col1'] == df['col2']).all()\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas testing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Series are different\n\nAttribute \"name\" are different\n[left]:  col1\n[right]: col2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0f45405f56d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'col2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_series_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'col2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[1;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Series are different\n\nAttribute \"name\" are different\n[left]:  col1\n[right]: col2"
     ]
    }
   ],
   "source": [
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'col1':[1, 2, 3, 4,5], 'col2':[1, 2, 3, 4, 5]})\n",
    "\n",
    "df2 = pd.DataFrame({'col1':[1, 2, 3, 4,5], 'col2':[1, 2, 3, 4, 5]})\n",
    "\n",
    "tm.assert_series_equal(df1['col1'], df2['col2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking a dataframe to a dictionary through a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "zillow_allhomes_df  = pd.read_csv(r'City_Zhvi_AllHomes.csv')\n",
    "zillow_allhomes_df.head()\n",
    "\n",
    "zillow_allhomes_df.loc[:, 'State'] = zillow_allhomes_df.loc[:, 'State'].map(states)\n",
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado'\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby and Pivots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "\n",
    "    \n",
    "<p>Techniques for Working with Pivots¶\n",
    "<p>Add a new column so that that counts can be displayed based on its unique values (This is for two column dfs)\n",
    "<p>Pivot the table with index, columns and counts as values\n",
    "<p>Flatten the multilevel column index    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Group by \n",
    "<code style=\"background:grey;color:black\">\n",
    "dropMean_df = df.groupby('Team').agg({'Drops':'mean'})\n",
    "    \n",
    "    \n",
    "Name the column in GroupBy\n",
    "df.groupby('kind').agg(min_height=('height', 'min'), \n",
    "                               max_weight=('weight', 'max'))\n",
    "    \n",
    "    \n",
    "df.groupby('Sex').agg(count_of_each=('Sex','count'))    \n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the pivot and merge multilevel index\n",
    "\n",
    "<code style=\"background:grey;color:black\">\n",
    "outcome_df = df.pivot_table(values=['Result'], index=['Group'], columns= ['Outcome'], aggfunc=['count'])\n",
    "#Combine the multilevel column name into one    \n",
    "outcome_df.columns = ['_'.join(col).strip() for col in outcome_df.columns.values]\n",
    "    \n",
    "#get the size of each group\n",
    "ratings_by_title = merged_df.groupby('title').size()\n",
    "    \n",
    "    \n",
    "Accessing mutilevel columns\n",
    "    \n",
    " We can see the columns are hierarchical. The top level column indices have two categories: mean and max, and\n",
    " the lower level column indices have four categories, which are the four rank levels. How would we query this\n",
    " if we want to get the average scores of First Tier Top Unversity levels in each country? We would just need\n",
    " to make two dataframe projections, the first for the mean, then the second for the top tier\n",
    "new_df['mean']['First Tier Top Unversity'].head()\n",
    "    \n",
    "    \n",
    "    \n",
    "Multilevel index\n",
    "    \n",
    "If we want to see the population results from Washtenaw County in Michigan the state, which is \n",
    "where I live, the first argument would be Michigan and the second would be Washtenaw County\n",
    "df.loc['Michigan', 'Washtenaw County']\n",
    "    \n",
    "If you are interested in comparing two counties, for example, Washtenaw and Wayne County, we can \n",
    " pass a list of tuples describing the indices we wish to query into loc. Since we have a MultiIndex \n",
    " of two values, the state and the county, we need to provide two values as each element of our \n",
    " filtering list. Each tuple should have two elements, the first element being the first index and \n",
    " the second element being the second index.\n",
    "\n",
    " Therefore, in this case, we will have a list of two tuples, in each tuple, the first element is \n",
    " Michigan, and the second element is either Washtenaw County or Wayne County\n",
    "\n",
    "df.loc[ [('Michigan', 'Washtenaw County'),\n",
    "         ('Michigan', 'Wayne County')] ]   \n",
    "    \n",
    "    \n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anti-join\n",
    "<code>\n",
    "import pandas as pd\n",
    "\n",
    "def anti_join(x, y, on):\n",
    "    \"\"\"Return rows in x which are not present in y\"\"\"\n",
    "    ans = pd.merge(left=x, right=y, how='left', indicator=True, on=on)\n",
    "    ans = ans.loc[ans._merge == 'left_only', :].drop(columns='_merge')\n",
    "    return ans\n",
    "\n",
    "\n",
    "def anti_join_all_cols(x, y):\n",
    "    \"\"\"Return rows in x which are not present in y\"\"\"\n",
    "    assert set(x.columns.values) == set(y.columns.values)\n",
    "    return anti_join(x, y, x.columns.tolist())\n",
    "    \n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new row at bottom of pivot dataframe\n",
    "<code style=\"background:grey;color:black\">\n",
    "new_row = {'Group' :'Observed_Difference' , 'count_Result_Failure' : FailureDiff, 'count_Result_Success': SuccessDiff, 'Total Count' : TotalDiff, 'avg_Success' : AvgDiff}\n",
    "outcome_df = outcome_df.append(new_row, ignore_index=True)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding margin totals to a pivot\n",
    "\n",
    "`df.pivot_table(values=['Price', 'Rating'], index='Manufacturer', columns='Bike Type', aggfunc=[np.mean], margins=True)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Using Where`\n",
    "*     Create a new column called based on the value of another column\n",
    "`df[\"Outcome\"] = np.where(df['Result'] == 0, 'Failure', 'Success')`\n",
    "\n",
    "` Three level nesting with np.where`\n",
    "`np.where(if_this_condition_is_true_one, do_this, \n",
    "  np.where(if_this_condition_is_true_two, do_that, \n",
    "    np.where(if_this_condition_is_true_three, do_foo, do_bar)))`\n",
    "    \n",
    "\n",
    "*  Using Between\n",
    "\n",
    "    `bool_series = data[\"Salary\"].between(80000, 100000, inclusive = True) \n",
    "    \n",
    "    \n",
    "Extension of where \n",
    "\n",
    " Here's my solution, I'm going to create a function called create_category which will operate on the first\n",
    " column in the dataframe, world_rank\n",
    "def create_category(ranking):\n",
    "    # Since the rank is just an integer, I'll just do a bunch of if/elif statements\n",
    "    if (ranking >= 1) & (ranking <= 100):\n",
    "        return \"First Tier Top Unversity\"\n",
    "    elif (ranking >= 101) & (ranking <= 200):\n",
    "        return \"Second Tier Top Unversity\"\n",
    "    elif (ranking >= 201) & (ranking <= 300):\n",
    "        return \"Third Tier Top Unversity\"\n",
    "    return \"Other Top Unversity\"\n",
    "\n",
    "Now we can apply this to a single column of data to create a new series\n",
    "df['Rank_Level'] = df['world_rank'].apply(lambda x: create_category(x))\n",
    " And lets look at the result\n",
    "df.head()\n",
    "    \n",
    "    \n",
    "`  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rowwise/along row stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:grey;color:black\">\n",
    "Send the row in to this function using apply\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\">\n",
    "def row_stats(row):\n",
    "    data = row[['count_Result_Success','count_Result_Failure']]\n",
    "    return pd.Series({'Total Count': np.sum(data)})\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\">\n",
    "apply the function to each row, note the axis\n",
    "outcome_df['Total Count'] = outcome_df.apply(row_stats, axis = 1)\n",
    "\n",
    "</code>    \n",
    "\n",
    "\n",
    "## Here's an example where we have a revised version of the function min_max Instead of returning a separate series to display the min and max we add two new columns in the original dataframe tostore min and max\n",
    "<code>\n",
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    # Create a new entry for max\n",
    "    row['max'] = np.max(data)\n",
    "    # Create a new entry for min\n",
    "    row['min'] = np.min(data)\n",
    "    return row\n",
    "# Now just apply the function across the dataframe\n",
    "df.apply(min_max, axis='columns')\n",
    "    \n",
    "</code>  \n",
    "### Here's You can imagine how you might chain several apply calls with lambdas together to create a readable  yet succinct data manipulation script. One line example of how you might calculate the max of the columns  using the apply function.\n",
    "<code>\n",
    "rows = ['POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013','POPESTIMATE2014', \n",
    "        'POPESTIMATE2015']\n",
    "df.apply(lambda x: np.max(x[rows]), axis=1).head()\n",
    "    \n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire dataframe stats - note the axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:grey;color:black\">\n",
    "df.mean(axis = 1) # Along the columns\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text file with hierachical data - states followed by cities cleaned to state-city columns\n",
    "\n",
    "<code style=\"background:grey;color:black\">\n",
    "  state_town_tuple_list = []\n",
    "    with open(r'university_towns.txt') as fref:\n",
    "        for line in fref:\n",
    "            lineWithoutSquare = line.split('[')[0].strip()\n",
    "            if ':' in lineWithoutSquare and not ('(')  in lineWithoutSquare :\n",
    "                continue\n",
    "            else:\n",
    "                if not ('(')  in lineWithoutSquare:\n",
    "                    state = lineWithoutSquare\n",
    "                else:\n",
    "                    univTown = lineWithoutSquare.split(' (')[0].strip().split(',')[0].strip()\n",
    "                    state_town_tuple_list.append((state, univTown) )\n",
    "</code>    \n",
    "<code style=\"background:grey;color:black\">               \n",
    "        state_univtown_df = pd.DataFrame(state_town_tuple_list, columns =['State', 'RegionName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absent data or Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame({'a': ['1?', '2?', '3'], 'b': ['4?', '?', '6?']})\n",
    "    \n",
    " print(df)\n",
    "\n",
    "df.replace({r'?': np.NaN}, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find what is at a certain row and column\n",
    "<code>\n",
    "df.at[df.index[df['Country'] == 'Africa'].values[0], 'Total confirmed cases']\n",
    "<code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify header, number of lines from bottom to ignore and drop columns and rows\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
    "</div>\n",
    "<code style=\"background:grey;color:black\">\n",
    "GDP_qtr = pd.read_excel(r'gdplev.xls', skiprows= 5)\n",
    "GDP_qtr= GDP_qtr.dropna(axis=0,how='all').dropna(axis=1,how='all').iloc[:,3:]\n",
    "Only drop columns which have at least 90% non-NaNs\n",
    "df.dropna(thresh=int(df.shape[0] * .9), axis=1)\n",
    "</code>     \n",
    "<code style=\"background:grey;color:black\"> \n",
    "Drop columns\n",
    "    Create list comprehension of the columns you want to lose\n",
    "    columns_to_drop = [column_names[i] for i in [1, 3, 5]]\n",
    "</code>\n",
    "<code style=\"background:grey;color:black\"> \n",
    "     Drop unwanted columns\n",
    "    df.drop(columns_to_drop, inplace=True, axis=1)\n",
    "</code>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Iterating through a dataset\n",
    "<code style=\"background:grey;color:black\">\n",
    "    for i, row in GDP_qtr.iterrows():\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving data of a column and not the series\n",
    "\n",
    "`test.loc[:0, 1992] \n",
    "0   -8941.531897\n",
    "Name: 1992, dtype: float64    \n",
    "`    \n",
    "   \n",
    "`df['column'].item()\n",
    "-8941.531896942593    \n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LaTeX MATH\n",
    "\n",
    "Jupyter Notebooks’ Markdown cells support LateX for formatting mathematical equations. To tell Markdown to interpret your text as LaTex, surround your input with dollar signs like this:\n",
    "\n",
    "`$\\sqrt{k}$`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine Index for a certain column value\n",
    "\n",
    "`GDP_qtr[GDP_qtr['YearQuarters']==recessionStart].index.item()\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reading lines from a file\n",
    "\n",
    "` with open(r'university_towns.txt') as fref:\n",
    "        for line in fref:`\n",
    "        \n",
    "        \n",
    "`f.seek(n)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and joins\n",
    "\n",
    "* PeriodIndex columns need to be changed in value to STR for Merge and Joins\n",
    "\n",
    "     `month_names = pd.PeriodIndex(month_names, freq='Q') `\n",
    "\n",
    "    `temp_zillow.columns = month_names`\n",
    "    \n",
    "    `#Makes ure the data in the periodindex columns are converted to str so that Merge and Join do not throw an error  `\n",
    "    `temp_zillow.columns.values.astype('str')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of a merge\n",
    "\n",
    "` univ_towns_housing = pd.merge(housing_data, univ_towns, how=\"left\", left_index=True, right_index=True)\n",
    "   `\n",
    "#### [Double colon slicing in Python and Pandas ](https://stackoverflow.com/questions/3453085/what-is-double-colon-in-python-when-subscripting-sequences  )\n",
    "\n",
    "\n",
    "#### Checking if an index is Unique\n",
    "\n",
    "\n",
    "dup_ts.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String operations\n",
    "\n",
    "\n",
    "`[w for w in list if len(w) > 3]`\n",
    "\n",
    "*For Capitalized first letter\n",
    "`w.istitle(), isupper() .islower()`\n",
    "`.split, .strip()`\n",
    "\n",
    "`startswith(), endswith()`\n",
    "`t in s`\n",
    "\n",
    "`isalpha, isdigits(), isalnum()`\n",
    "\n",
    "`s.lower(), s.upper()m s.titlecase()`\n",
    "\n",
    "`s.splitlines()`\n",
    "`s.join(t)`\n",
    "\n",
    "`s.strip(), s.rstrip()   will also remove new line character`\n",
    "\n",
    "`s.find(), s.rfind()`\n",
    "\n",
    "`list(someword)  splits the word into characters   or [c for c in someword]`\n",
    "\n",
    "`s.replace('o', 'O')`\n",
    "\n",
    "`[w  for w in somelist of delimited words if w.startswith('#')]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular expression\n",
    "\n",
    "`import re`\n",
    "\n",
    "`re.search('[a-zA-A0-9_]+', s)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating a new column using ASSIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.assign(text_length = df['text'].apply(len))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the value counts for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = auto_prices['make'].value_counts() # find the counts for each unique category\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Unicodes and Dedpes using ML\n",
    "[Click here to check out the Unicodes section ](https://medium.com/@rrfd/cleaning-and-prepping-data-with-python-for-data-science-best-practices-and-helpful-packages-af1edfbe2a3)\n",
    "\n",
    "https://medium.com/district-data-labs/basics-of-entity-resolution-with-python-and-dedupe-bc87440b64d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram bins with value_counts() similar to pd.cut\n",
    "\n",
    "train['Fare'].value_counts(bins=7)\n",
    "\n",
    "\n",
    "#### [Reverse columns and rows of a dataframe](https://www.marsja.se/six-ways-to-reverse-pandas-dataframe)\n",
    "\n",
    "In the code example below, the second line (columns[::-1]) reverse the list of column names. \n",
    "<code>\n",
    "columns = data_frame.columns.tolist()\n",
    "columns = columns[::-1]\n",
    "data_frame = data_frame[columns]\n",
    "</code>\n",
    "\n",
    "<code>\n",
    "data_frame = data_frame.sort_index(axis=1 ,ascending=True)\n",
    "First, we will use iloc which is integer based to reverse the order of the Pandas dataframe:\n",
    "\n",
    "data_frame = data_frame.iloc[::-1]\n",
    "    \n",
    "Lastly, we can also use the method reindex to reverse by row. This will sort Pandas Dataframe reversed. That is, the last element will be first.\n",
    "\n",
    "data_frame = data_frame.reindex(index=data_frame.index[::-1])\n",
    "data_frame.head()    \n",
    "</code>\n",
    "\n",
    "#### When you have dataframes ebing create by reading a series of files (say PDFs or CSVs it is best to create a list of dataframes and concat them together\n",
    "pd.concat(df_list)\n",
    "\n",
    "\n",
    "#### Pattern for reading a series of CSV or text files\n",
    "<li> Note that some TEXT and CSV file maight not have headers or might have unacceptable headers and so set the column names explicitly </li>\n",
    "<li> when concatenating a list fo dataframe set ignore_index - true to have a continuous series</li>\n",
    "<li> Initialize the list in the same cell as the loop (so it is definitely initialized in multiple runs!!!</li>\n",
    "<code>\n",
    "df_list = []\n",
    "for year in range(1880, 2011):  \n",
    "    filename = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/datasets/babynames/yob'+str(year)+'.txt'\n",
    "    try:\n",
    "        print(filename) \n",
    "        df = pd.read_csv(filename, header=None)\n",
    "        df.columns = ['Name', 'Gender', 'Births']\n",
    "        df['Year'] = year\n",
    "        print(df.shape[0])\n",
    "    except:\n",
    "        pass\n",
    "    if ~df.empty:\n",
    "        df_list.append(df)\n",
    "    \n",
    "final_df = pd.concat(df_list, ignore_index=True)    \n",
    "</code>    \n",
    "\n",
    "\n",
    "#### Grouping WITHOUT aggregation/ Grouping as a partition\n",
    "Since there is no aggregate function being called on the Group, the funcyion add_prop is applied to each element of a group. The Sum iss calculated per grouo partition\n",
    "\n",
    "All the columns of the dataset are retained\n",
    "\n",
    "<code>\n",
    "def add_prop(group):\n",
    "    group['prop'] = group.births / group.births.sum()\n",
    "    return group\n",
    "names = names.groupby(['year', 'sex']).apply(add_prop)\n",
    "</code>    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### Formatting datetime table\n",
    "Table 11-2. Datetime format specification (ISO C89 compatible)\n",
    "\n",
    "Type\tDescription\n",
    "\n",
    "%Y\tFour-digit year\n",
    "\n",
    "%y\tTwo-digit year\n",
    "\n",
    "%m\tTwo-digit month [01, 12]\n",
    "\n",
    "%d\tTwo-digit day [01, 31]\n",
    "\n",
    "%H\tHour (24-hour clock) [00, 23]\n",
    "\n",
    "%I\tHour (12-hour clock) [01, 12]\n",
    "\n",
    "%M\tTwo-digit minute [00, 59]\n",
    "\n",
    "%S\tSecond [00, 61] (seconds 60, 61 account for leap seconds)\n",
    "\n",
    "%w\tWeekday as integer [0 (Sunday), 6]\n",
    "\n",
    "%U\tWeek number of the year [00, 53]; Sunday is considered the first day of the week, and days before the first Sunday of \n",
    "the year are “week 0”\n",
    "\n",
    "%W\tWeek number of the year [00, 53]; Monday is considered the first day of the week, and days before the first Monday of the year are “week 0”\n",
    "\n",
    "%z\tUTC time zone offset as +HHMM or -HHMM; empty if time zone naive\n",
    "\n",
    "%F\tShortcut for %Y-%m-%d (e.g., 2012-4-18)\n",
    "\n",
    "%D\tShortcut for %m/%d/%y (e.g., 04/18/12)\n",
    "\n",
    "\n",
    "datetime.strptime is a good way to parse a date with a known format. However, it can be a bit annoying to have to write a format spec each time, especially for common date formats. In this case, you can use the parser.parse method in the third-party dateutil package (this is installed automatically when you install pandas):\n",
    "\n",
    "In [31]: from dateutil.parser import parse\n",
    "\n",
    "In [32]: parse('2011-01-03')\n",
    "Out[32]: datetime.datetime(2011, 1, 3, 0, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group By and Filtering\n",
    "\n",
    "<code>\n",
    " # For instance, if we only want those groups which have a mean rating above 9 included in our results\n",
    "df.groupby('cancellation_policy').filter(lambda x: np.nanmean(x['review_scores_value'])>9.2)   \n",
    "</code>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform\n",
    "\n",
    "<code>\n",
    " # First, lets define just some subset of columns we are interested in\n",
    "cols=['cancellation_policy','review_scores_value']\n",
    "# Now lets transform it, I'll store this in its own dataframe\n",
    "transform_df=df[cols].groupby('cancellation_policy').transform(np.nanmean)\n",
    "transform_df.head()\n",
    "    \n",
    "So we can see that the index here is actually the same as the original dataframe. So lets just join this\n",
    "in. Before we do that, lets rename the column in the transformed version\n",
    "transform_df.rename({'review_scores_value':'mean_review_scores'}, axis='columns', inplace=True)\n",
    "df=df.merge(transform_df, left_index=True, right_index=True)\n",
    "df.head()    \n",
    "    \n",
    "    \n",
    "</code>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "myindex=pd.date_range(start='1/1/2020', end='1/31/2020')\n",
    "a = [i for i in range(len(myindex))]\n",
    "df = pd.DataFrame(a, index=myindex)\n",
    "df['Weekday'] = df.index.weekday\n",
    "\n",
    "# Monday is 0 and Sunday is 6  \n",
    "\n",
    "#pd.DateFrame(index=pd.date_range(start='1/1/2020', end='1/31/2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-11</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-15</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-18</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-27</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-28</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-29</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-30</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  Weekday\n",
       "2020-01-01   0        2\n",
       "2020-01-02   1        3\n",
       "2020-01-03   2        4\n",
       "2020-01-04   3        5\n",
       "2020-01-05   4        6\n",
       "2020-01-06   5        0\n",
       "2020-01-07   6        1\n",
       "2020-01-08   7        2\n",
       "2020-01-09   8        3\n",
       "2020-01-10   9        4\n",
       "2020-01-11  10        5\n",
       "2020-01-12  11        6\n",
       "2020-01-13  12        0\n",
       "2020-01-14  13        1\n",
       "2020-01-15  14        2\n",
       "2020-01-16  15        3\n",
       "2020-01-17  16        4\n",
       "2020-01-18  17        5\n",
       "2020-01-19  18        6\n",
       "2020-01-20  19        0\n",
       "2020-01-21  20        1\n",
       "2020-01-22  21        2\n",
       "2020-01-23  22        3\n",
       "2020-01-24  23        4\n",
       "2020-01-25  24        5\n",
       "2020-01-26  25        6\n",
       "2020-01-27  26        0\n",
       "2020-01-28  27        1\n",
       "2020-01-29  28        2\n",
       "2020-01-30  29        3\n",
       "2020-01-31  30        4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>105</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>154</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  Weekday\n",
       "2020-01-05   10       20\n",
       "2020-01-12   56       21\n",
       "2020-01-19  105       21\n",
       "2020-01-26  154       21\n",
       "2020-02-02  140       10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W', closed = 'right').sum()\n",
    "#The value of the end of the week which is Sunday 05 IS included\n",
    "# ‘W’ which all have a default of ‘right' for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>147</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>165</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  Weekday\n",
       "2020-01-05    6       14\n",
       "2020-01-12   49       21\n",
       "2020-01-19   98       21\n",
       "2020-01-26  147       21\n",
       "2020-02-02  165       16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W', closed = 'left').sum()\n",
    "# The value of the end of the week (Sunday which is the teh right end is NOT included)\n",
    "# Default label is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>105</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>154</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  Weekday\n",
       "2019-12-29   10       20\n",
       "2020-01-05   56       21\n",
       "2020-01-12  105       21\n",
       "2020-01-19  154       21\n",
       "2020-01-26  140       10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W', closed = 'right', label='left').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>98</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>147</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>165</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  Weekday\n",
       "2019-12-29    6       14\n",
       "2020-01-05   49       21\n",
       "2020-01-12   98       21\n",
       "2020-01-19  147       21\n",
       "2020-01-26  165       16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W', closed = 'left', label='left').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= 'alert alert-block alert-warning'>\n",
    "  <h3>Prof Chris Brooks Tips and Tricks</h3>           \n",
    "</div>             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>partner</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>casey</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>casey</td>\n",
       "      <td>john</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samantha</td>\n",
       "      <td>adam</td>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>samantha</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rupal</td>\n",
       "      <td>zihan</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zihan</td>\n",
       "      <td>rupal</td>\n",
       "      <td>84</td>\n",
       "      <td>67</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   partner  a1  a2   a3\n",
       "0      john     casey  80  90  100\n",
       "1     casey      john  88  60   89\n",
       "2  samantha      adam  82  95   40\n",
       "3      adam  samantha  84  70   89\n",
       "4     rupal     zihan  60  90  100\n",
       "5     zihan     rupal  84  67  105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "attendees=[\n",
    "    {\"name\":\"john\",\"partner\":\"casey\",\"a1\":80,\"a2\":90,\"a3\":100},\n",
    "    {\"name\":\"casey\",\"partner\":\"john\",\"a1\":88,\"a2\":60,\"a3\":89},\n",
    "    {\"name\":\"samantha\",\"partner\":\"adam\",\"a1\":82,\"a2\":95,\"a3\":40},\n",
    "    {\"name\":\"adam\",\"partner\":\"samantha\",\"a1\":84,\"a2\":70,\"a3\":89},\n",
    "    {\"name\":\"rupal\",\"partner\":\"zihan\",\"a1\":60,\"a2\":90,\"a3\":100},\n",
    "    {\"name\":\"zihan\",\"partner\":\"rupal\",\"a1\":84,\"a2\":67,\"a3\":105}]\n",
    "df=pd.DataFrame(attendees)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_x</th>\n",
       "      <th>partner_x</th>\n",
       "      <th>a1_x</th>\n",
       "      <th>a2_x</th>\n",
       "      <th>a3_x</th>\n",
       "      <th>name_y</th>\n",
       "      <th>partner_y</th>\n",
       "      <th>a1_y</th>\n",
       "      <th>a2_y</th>\n",
       "      <th>a3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>casey</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>casey</td>\n",
       "      <td>john</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>casey</td>\n",
       "      <td>john</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>john</td>\n",
       "      <td>casey</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samantha</td>\n",
       "      <td>adam</td>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>adam</td>\n",
       "      <td>samantha</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>samantha</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>samantha</td>\n",
       "      <td>adam</td>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rupal</td>\n",
       "      <td>zihan</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>zihan</td>\n",
       "      <td>rupal</td>\n",
       "      <td>84</td>\n",
       "      <td>67</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zihan</td>\n",
       "      <td>rupal</td>\n",
       "      <td>84</td>\n",
       "      <td>67</td>\n",
       "      <td>105</td>\n",
       "      <td>rupal</td>\n",
       "      <td>zihan</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name_x partner_x  a1_x  a2_x  a3_x    name_y partner_y  a1_y  a2_y  a3_y\n",
       "0      john     casey    80    90   100     casey      john    88    60    89\n",
       "1     casey      john    88    60    89      john     casey    80    90   100\n",
       "2  samantha      adam    82    95    40      adam  samantha    84    70    89\n",
       "3      adam  samantha    84    70    89  samantha      adam    82    95    40\n",
       "4     rupal     zihan    60    90   100     zihan     rupal    84    67   105\n",
       "5     zihan     rupal    84    67   105     rupal     zihan    60    90   100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.merge(df,df,left_on=\"name\",right_on=\"partner\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_x</th>\n",
       "      <th>name_y</th>\n",
       "      <th>grade_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "      <td>casey</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>casey</td>\n",
       "      <td>john</td>\n",
       "      <td>-11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samantha</td>\n",
       "      <td>adam</td>\n",
       "      <td>-8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>samantha</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rupal</td>\n",
       "      <td>zihan</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zihan</td>\n",
       "      <td>rupal</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name_x    name_y  grade_difference\n",
       "0      john     casey         11.000000\n",
       "1     casey      john        -11.000000\n",
       "2  samantha      adam         -8.666667\n",
       "3      adam  samantha          8.666667\n",
       "4     rupal     zihan         -2.000000\n",
       "5     zihan     rupal          2.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"grade_difference\"]=df.apply(lambda x: np.sum(x[[\"a1_x\",\"a2_x\",\"a3_x\"]])/3 - np.sum(x[[\"a1_y\",\"a2_y\",\"a3_y\"]])/3, axis=1)\n",
    "display(df[[\"name_x\",\"name_y\",\"grade_difference\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>url</th>\n",
       "      <th>architecture</th>\n",
       "      <th>amazon-product-upc-redirect</th>\n",
       "      <th>machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-06T23:54:07</td>\n",
       "      <td>Mozilla/5.0 (Windows; U; Windows NT 4.0) Apple...</td>\n",
       "      <td>https://www.sherman-jones.com/</td>\n",
       "      <td>x86_64</td>\n",
       "      <td>944548002112</td>\n",
       "      <td>140.34.91.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-05-30T14:03:41</td>\n",
       "      <td>Opera/9.96.(Windows 98; sa-IN) Presto/2.9.189 ...</td>\n",
       "      <td>https://odonnell.com/app/category.html</td>\n",
       "      <td>i686</td>\n",
       "      <td>597494845458</td>\n",
       "      <td>196.25.229.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-22T07:12:05</td>\n",
       "      <td>Opera/8.19.(X11; Linux x86_64; mk-MK) Presto/2...</td>\n",
       "      <td>https://www.simpson.net/privacy/</td>\n",
       "      <td>i686</td>\n",
       "      <td>353480306118</td>\n",
       "      <td>133.44.208.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-12T16:05:07</td>\n",
       "      <td>Opera/9.21.(Windows NT 5.2; nds-DE) Presto/2.9...</td>\n",
       "      <td>https://vazquez.com/category/</td>\n",
       "      <td>i686</td>\n",
       "      <td>908827286259</td>\n",
       "      <td>102.13.146.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-11-12T16:34:29</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux i686; rv:1.9.5.20) Gec...</td>\n",
       "      <td>http://www.baker.info/</td>\n",
       "      <td>x86_64</td>\n",
       "      <td>385563144997</td>\n",
       "      <td>196.95.7.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime                                         user_agent  \\\n",
       "0  2010-07-06T23:54:07  Mozilla/5.0 (Windows; U; Windows NT 4.0) Apple...   \n",
       "1  1998-05-30T14:03:41  Opera/9.96.(Windows 98; sa-IN) Presto/2.9.189 ...   \n",
       "2  2019-12-22T07:12:05  Opera/8.19.(X11; Linux x86_64; mk-MK) Presto/2...   \n",
       "3  2012-01-12T16:05:07  Opera/9.21.(Windows NT 5.2; nds-DE) Presto/2.9...   \n",
       "4  2003-11-12T16:34:29  Mozilla/5.0 (X11; Linux i686; rv:1.9.5.20) Gec...   \n",
       "\n",
       "                                      url architecture  \\\n",
       "0          https://www.sherman-jones.com/       x86_64   \n",
       "1  https://odonnell.com/app/category.html         i686   \n",
       "2        https://www.simpson.net/privacy/         i686   \n",
       "3           https://vazquez.com/category/         i686   \n",
       "4                  http://www.baker.info/       x86_64   \n",
       "\n",
       "  amazon-product-upc-redirect         machine  \n",
       "0                944548002112   140.34.91.163  \n",
       "1                597494845458  196.25.229.172  \n",
       "2                353480306118   133.44.208.74  \n",
       "3                908827286259  102.13.146.149  \n",
       "4                385563144997    196.95.7.223  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "df=pd.DataFrame([{\"datetime\":fake.iso8601(),\n",
    "                  \"user_agent\":fake.user_agent(),\n",
    "                  \"url\":fake.uri(), \n",
    "                  \"architecture\":fake.linux_processor(),\n",
    "                  \"amazon-product-upc-redirect\": fake.upc_a(),\n",
    "                  \"machine\":fake.ipv4()} for x in range(10000)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                       object\n",
       "user_agent                     object\n",
       "url                            object\n",
       "architecture                   object\n",
       "amazon-product-upc-redirect    object\n",
       "machine                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime                        760000\n",
      "user_agent                     1491423\n",
      "url                             920090\n",
      "architecture                    620152\n",
      "amazon-product-upc-redirect     690000\n",
      "machine                         702394\n",
      "dtype: int64\n",
      "5184059 bytes in total size\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print( df.memory_usage(deep=True, index=False) )\n",
    "print( f\"{np.sum(df.memory_usage(deep=True, index=False))} bytes in total size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a copy for a comparison later\n",
    "new_df=df.copy(deep=True)\n",
    "\n",
    "# let's change the datetime field from strings to a timestamp\n",
    "new_df[\"datetime\"]=pd.to_datetime(new_df[\"datetime\"])\n",
    "\n",
    "# there are only a handful of values for the architecture column, so lets change this to categories\n",
    "new_df[\"architecture\"]=new_df[\"architecture\"].astype('category')\n",
    "\n",
    "# one option involves changing data to fit a type better. That UPC code is just a string of digits, can we convert this\n",
    "# to an integer to store them? What is the downside of this approach?\n",
    "new_df[\"amazon-product-upc-redirect\"] = new_df[\"amazon-product-upc-redirect\"].astype(int)\n",
    "\n",
    "# we can go much further if we wanted to, and it depends on how someone is going to query data. For instance, an IPv4\n",
    "# address is actually just four bytes of information - numbers 1-255 four times in a row. But the string representation\n",
    "# (called a \"dotted quad\") is massive, up to 16 characters and in unicode these could be 4 bytes a piece!\n",
    "from ipaddress import IPv4Address\n",
    "new_df[\"machine\"]=new_df[\"machine\"].apply(lambda x: int.from_bytes(IPv4Address(x).packed, byteorder='big'))\n",
    "\n",
    "# Let's take a look at what this looks like to the eye:\n",
    "display(new_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute savings in bytes\n",
    "display(df.memory_usage(deep=True, index=False)-new_df.memory_usage(deep=True, index=False))\n",
    "\n",
    "# size as a percentage of original\n",
    "display(new_df.memory_usage(deep=True, index=False)/df.memory_usage(deep=True, index=False)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We wouldn't expect to see differences in the user_agent and url but we do see significant memory savings on all of the columns, which clock in at about 10% of the size of the original data except for the one which we changed to categorical data which is now highly compressed at under 2% of original size!\n",
    "\n",
    "So what's this mean for performance? I don't know -- why don't you use the skills you've learned thus far, and use of %%timeit to investigate and report out on slack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change datatype from dataframe to array \n",
    "x = nyc['distance'].values.reshape((-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert BGR to RGB\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  TIPS AND TRICKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<h4> Pretty Print </h4>    \n",
    "<p>import pprint as pp\n",
    "<p>pp.pprint (df)\n",
    "\n",
    "    \n",
    "<h4> Undo a delete </h4>    \n",
    " <li> Contents :  CTRL + Z</li>\n",
    " <li> Entire Cell :  ESC+Z  </li>   \n",
    "\n",
    "    \n",
    "<li> Esc + M to create a markdown\n",
    "    \n",
    "<li> Shift + Enter to run and create new cell below </li>    \n",
    "    \n",
    "<li> Find the dataframes in a notebook </li>\n",
    "    \n",
    "<p> listDF = %who_ls DataFrame </p>\n",
    "<h4> Display Options </h4> \n",
    "<div>    \n",
    "<p>pd.set_option('display.max_columns', 10)\n",
    "<p>pd.set_option('display.max_rows', 10)\n",
    "</div>\n",
    "    \n",
    "    \n",
    "<h4> Find and replace in all cells in Jupyter notebook </h4>\n",
    "    * Edit-> Find and replace Click double sided arrow\n",
    "    \n",
    "    \n",
    "<h4> Error Source </h4>\n",
    "   <li> Using variables from a previous cell and not noticiing it has been initialized or changing a variable name in one cell and not noticing/applying the change in a lower cell\n",
    "   <li> Initialize an empty list in the same cell as you use it\n",
    "    \n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "py_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
